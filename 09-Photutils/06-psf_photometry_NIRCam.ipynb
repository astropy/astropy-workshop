{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/photutils_banner.svg\" width=500 alt=\"Photutils logo\" style=\"margin-left: 0;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h2 style=\"margin-top: 0\">In this notebook, we will cover:</h2>\n",
    "\n",
    "- PSF photometry extracting PSFs from an input image\n",
    "    - Using a simulated image of elliptical PSFs\n",
    "    - Using a simulated JWST NIRCam image\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSF photometry using an image-based PSF Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Change some default plotting parameters\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['image.origin'] = 'lower'\n",
    "mpl.rcParams['image.interpolation'] = 'nearest'\n",
    "\n",
    "# Run the %matplotlib magic command to enable inline plotting\n",
    "# in the current notebook.  Choose one of these:\n",
    "%matplotlib inline\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a simulated image (without noise) with a funky elliptical Moffat-like PSF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's create the PSF model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from photutils import psf\n",
    "from astropy.modeling import models\n",
    "\n",
    "psfmodel = ((models.Shift(-5) & models.Shift(2)) | \n",
    "            models.Rotation2D(-20) | \n",
    "            (models.Identity(1) & models.Scale(1.5)) | \n",
    "            models.Moffat2D(1, 0, 0, 6, 4.76))\n",
    "\n",
    "psfmodel.bounding_box = ((-10, 10), (-10, 10))\n",
    "psfmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display this PSF model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psfim = psfmodel.render().T\n",
    "plt.imshow(psfim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create a simulated image of sources using this PSF model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psfmodel.offset_0 = psfmodel.offset_1 = 0\n",
    "if hasattr(psfmodel, 'bounding_box'):\n",
    "    psfimcen = psfmodel.render()\n",
    "    del psfmodel.bounding_box\n",
    "\n",
    "rng = np.random.default_rng(seed=123)\n",
    "\n",
    "data = np.zeros((100, 100))\n",
    "amps = rng.standard_normal(100)**2\n",
    "xs = rng.uniform(0, data.shape[0], size=amps.size)\n",
    "ys = rng.uniform(0, data.shape[1], size=amps.size)\n",
    "\n",
    "for x, y, amp in zip(xs, ys, amps):\n",
    "    psfmodel.amplitude_3 = amp\n",
    "    psfmodel.offset_1 = -x\n",
    "    psfmodel.offset_0 = -y\n",
    "    psfmodel.render(data)\n",
    "\n",
    "axim = plt.imshow(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we use  `FittableImageModel` on a *rendered* version of the PSF model with no pixel subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(psfimcen)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psf_im_model = psf.FittableImageModel(psfimcen, normalize=1)\n",
    "psf_im_model.bounding_box = ((-10, 10), (-10, 10))\n",
    "psfrendered = psf_im_model.render()\n",
    "del psf_im_model.bounding_box\n",
    "\n",
    "plt.imshow(psfrendered)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's try doing photometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to find stars.  We'll use the DAOPhot algorithm (which at its core is the same as most other PSF photometry tools)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we estimate the variance in the image to give us some guess as to what might be a good threshold for star-finding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.stats import SigmaClip\n",
    "from photutils.background import BiweightScaleBackgroundRMS\n",
    "\n",
    "bkg_var = BiweightScaleBackgroundRMS(sigma_clip=SigmaClip(3))(data)\n",
    "bkg_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create a `DAOStarFinder` object and run that on the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from photutils.detection import DAOStarFinder\n",
    "\n",
    "star_finder = DAOStarFinder(threshold=bkg_var/2, fwhm=5)\n",
    "found_stars = star_finder(data)\n",
    "\n",
    "plt.imshow(data)\n",
    "plt.scatter(found_stars['xcentroid'], found_stars['ycentroid'], color='red', s=5)\n",
    "\n",
    "found_stars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we create the object to do the photometry, and run it on the table of stars we found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph = psf.BasicPSFPhotometry(psf.DAOGroup(10), None, psf_im_model, \n",
    "                            (5, 5), aperture_radius=10)\n",
    "\n",
    "if 'xcentroid' in found_stars.colnames:\n",
    "    # there's an if here simply to make sure you can run this cell\n",
    "    # multiple times without re-running the star finder\n",
    "    found_stars['xcentroid'].name = 'x_0'\n",
    "    found_stars['ycentroid'].name = 'y_0'\n",
    "    found_stars['flux'].name = 'flux_0'\n",
    "\n",
    "res = ph.do_photometry(data, init_guesses=found_stars)\n",
    "\n",
    "\n",
    "plt.imshow(data)\n",
    "plt.colorbar()\n",
    "plt.scatter(res['x_0'], res['y_0'], color='k')\n",
    "plt.scatter(res['x_fit'], res['y_fit'], color='r', s=3, lw=0)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we try making a residual image to see how well it did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "vmin, vmax = -0.3, 2.0\n",
    "\n",
    "ax1.imshow(data, vmin=vmin, vmax=vmax)\n",
    "ax2.imshow(ph.get_residual_image(), vmin=vmin, vmax=vmax)\n",
    "ax2.scatter(res['x_fit'], res['y_fit'], color='r', s=3, lw=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well that looks OK except that it looks ugly because our psf model that we fit was a bit small.  So let's try subtracting the *actual* model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtracted_image = psf.subtract_psf(data, psf_im_model, res)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "vmin, vmax = -0.3, 2.0\n",
    "\n",
    "ax1.imshow(data, vmin=vmin, vmax=vmax)\n",
    "ax2.imshow(subtracted_image, vmin=vmin, vmax=vmax)\n",
    "ax2.scatter(res['x_fit'], res['y_fit'], color='r', s=3, lw=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Simulated JWST/NIRCam data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try something like the above, but with simulated JWST/NIRCam data, using an oversampled PSF.  \n",
    "\n",
    "In principal this is one of two modes one might take with real JWST data.  For many cases using a provided PSF (or generated from `webbpsf`) will be sufficient.  `photutils` also has a high-level tool to build an effective PSF (ePSF) directly from the image (see https://photutils.readthedocs.io/en/latest/epsf.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from astropy import wcs\n",
    "from astropy.io import fits\n",
    "from astropy.utils.data import download_file\n",
    "\n",
    "# the simulated JWST/NIRCam data will be downloaded from STScI\n",
    "base_url = 'https://data.science.stsci.edu/redirect/JWST/jwst-data_analysis_tools/simulated_nircam_images/nircam_f210m/'\n",
    "im1_fn = 'simulated_nircam_f210m.fits'\n",
    "psf1_fn = 'simulated_nircam_f210m_psf.fits'\n",
    "im1_url = os.path.join(base_url, im1_fn)\n",
    "psf1_url = os.path.join(base_url, psf1_fn)\n",
    "\n",
    "im1_path = download_file(im1_url, cache=True, timeout=60)\n",
    "psf1_path = download_file(psf1_url, cache=True, timeout=60)\n",
    "\n",
    "with fits.open(im1_path) as im1f:\n",
    "    im1 = im1f[1].data.copy()\n",
    "    im1h = im1f[1].header.copy()\n",
    "    im1wcs = wcs.WCS(im1h)\n",
    "\n",
    "with fits.open(psf1_path) as psf1f:\n",
    "    psf1 = psf1f[0].data.copy()\n",
    "    psf1h = psf1f[0].header.copy()\n",
    "    psf1wcs = wcs.WCS(psf1h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a quick-and-easy way to rescale an image, using the \n",
    "# astropy.visualization package\n",
    "from astropy.visualization import simple_norm\n",
    "\n",
    "norm = simple_norm(im1, 'log', percent=99.0)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(im1, norm=norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, let's histogram it so we can see roughly where the threshold should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(im1.ravel(), bins=100, histtype='step', range=(-10, 200), log=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsf = DAOStarFinder(100, 5)\n",
    "found_stars = dsf(im1)\n",
    "found_stars['xcentroid'].name = 'x_0'\n",
    "found_stars['ycentroid'].name = 'y_0'\n",
    "found_stars['flux'].name = 'flux_0'\n",
    "found_stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(im1, norm=norm)\n",
    "plt.scatter(found_stars['x_0'], found_stars['y_0'], lw=0, s=3, c='k')\n",
    "plt.xlim(500, 1500)\n",
    "plt.ylim(500, 1500);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build the actual PSF model using the file that the PSF is given in. It is using external knowledge that the PSF is 5x oversampled. The simple oversampling below only works as-is because both are square, but that's true here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that this is *not* the same pixel scale as the image above\n",
    "plt.figure(figsize=(8, 8))\n",
    "psf_norm = simple_norm(psf1, 'log', percent=99.)\n",
    "\n",
    "plt.imshow(psf1, norm=psf_norm)\n",
    "\n",
    "psfmodel = psf.FittableImageModel(psf1, oversampling=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now zoom in on the image somewhere and see how the model looks compared to the actual image scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 10))\n",
    "\n",
    "ax1.imshow(im1, norm=norm)\n",
    "ax1.set_xlim(1080, 1131)\n",
    "ax1.set_ylim(1100, 1151)\n",
    "ax1.set_title('Simulated image')\n",
    "\n",
    "xg, yg = np.mgrid[-25:25, -25:25]\n",
    "psf_norm2 = simple_norm(psfmodel(xg, yg), 'log', percent=99.)\n",
    "ax2.imshow(psfmodel(xg, yg), norm=psf_norm2)\n",
    "ax2.set_title('PSF');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build a PSF photometry runner that is auto-configured to work basically the same as DAOPHOT.  All of the steps in photometry are customizable if you like, but for now we'll just use this because it's a familiar code to many people. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psfphot = psf.DAOPhotPSFPhotometry(crit_separation=5, \n",
    "                                   threshold=100, fwhm=5, \n",
    "                                   psf_model=psfmodel, fitshape=(9, 9),\n",
    "                                   niters=1, aperture_radius=5)\n",
    "results = psfphot(im1, init_guesses=found_stars[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's inspect the residual image as a whole, and zoomed in on a few particular stars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_im1 = psfphot.get_residual_image()\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "res_norm = simple_norm(res_im1, 'log', percent=99.)\n",
    "plt.imshow(res_im1, norm=res_norm)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these *should* be one by itself and one near the core.  But you might \n",
    "# have to change the (10, 500) to something else depending on what you\n",
    "# want to inspect\n",
    "for i in (10, 50): \n",
    "\n",
    "    resulti = results[i]\n",
    "    window_rad = 20\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 10))\n",
    "\n",
    "    ax1.imshow(im1, norm=norm)\n",
    "    ax1.set_xlim(resulti['x_fit']-window_rad, resulti['x_fit']+window_rad)\n",
    "    ax1.set_ylim(resulti['y_fit']-window_rad, resulti['y_fit']+window_rad)\n",
    "    ax1.scatter([resulti['x_0']], [resulti['y_0']], color='r', s=7)\n",
    "    ax1.scatter([resulti['x_fit']], [resulti['y_fit']], color='w', s=7)\n",
    "    ax1.set_title('Original image (star #{})'.format(i))\n",
    "\n",
    "    ax2.imshow(res_im1, norm=res_norm)\n",
    "    ax2.set_xlim(resulti['x_fit']-window_rad, resulti['x_fit']+window_rad)\n",
    "    ax2.set_ylim(resulti['y_fit']-window_rad, resulti['y_fit']+window_rad)\n",
    "    ax2.scatter([resulti['x_0']], [resulti['y_0']], color='r', s=7)\n",
    "    ax2.scatter([resulti['x_fit']], [resulti['y_fit']], color='w', s=7)\n",
    "    ax2.set_title('Subtracted image (star #{})'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, looks like at least some of them worked great, but in the crowded areas more iterations/tweaks to the input parameters are needed.  See if you can tweak the parameters to make it better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this simulated data set we only have one band, so there's not much output \"science\" to show... But below you see how to get out magnitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this zero-point is just a made-up number right now, \n",
    "# but it's something the instrument team will provide\n",
    "inst_mag = -2.5 * np.log10(results['flux_fit'])\n",
    "zero_point = 31.2  \n",
    "results['cal_mag'] = zero_point + inst_mag\n",
    "\n",
    "# if you scroll to the right you'll see the new column\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, particularly for brighter stars, the above procedure doesn't do well, primarily because the star finder doesn't find them efficiently along with the faint ones.  Try manually editing the `found_stars` table and by-hand insert a few bright stars.  See if you can get them to subtract well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try playing around with the various options and see if you can do better *automatically*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
