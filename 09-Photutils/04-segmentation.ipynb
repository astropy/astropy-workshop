{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"data/photutils_banner.svg\" width=500 alt=\"Photutils logo\" style=\"margin-left: 0;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h2 style=\"margin-top: 0\">In this notebook, we will cover:</h2>\n",
    "\n",
    "- The basics of image segmentation\n",
    "\n",
    "This notebook builds on the previous tutorials for Astropy Units/Quantities, Coordinates, FITS, and Tables.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Change some default plotting parameters\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['image.origin'] = 'lower'\n",
    "mpl.rcParams['image.interpolation'] = 'nearest'\n",
    "\n",
    "# Run the %matplotlib magic command to enable inline plotting\n",
    "# in the current notebook.  Choose one of these:\n",
    "%matplotlib inline\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We'll start by reading science data and error arrays from FITS files located in the [**data/**](data) subdirectory.  The FITS files contain 2D cutout images from the [Hubble Extreme-Deep Field (XDF)](https://archive.stsci.edu/prepds/xdf/) taken with the [Wide Field Camera 3 (WFC3)](https://www.stsci.edu/hst/instrumentation/wfc3) IR channel in the F160W filter (centered at ~1.6 $\\mu m$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "from photutils.utils import calc_total_error\n",
    "\n",
    "sci_fn = 'data/xdf_hst_wfc3ir_60mas_f160w_sci.fits'\n",
    "rms_fn = 'data/xdf_hst_wfc3ir_60mas_f160w_rms.fits'\n",
    "sci_hdulist = fits.open(sci_fn)\n",
    "rms_hdulist = fits.open(rms_fn)\n",
    "\n",
    "data = sci_hdulist[0].data.astype(float)\n",
    "error = rms_hdulist[0].data.astype(float)\n",
    "hdr = sci_hdulist[0].header\n",
    "wcs = WCS(hdr)\n",
    "\n",
    "eff_gain = hdr['TEXPTIME']  # exposure time from the FITS header\n",
    "total_error = calc_total_error(data, error, eff_gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.visualization import simple_norm\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "norm = simple_norm(data, 'sqrt', percent=99.)\n",
    "plt.imshow(data, norm=norm)\n",
    "plt.title('XDF F160W Cutout');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Image Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image segmentation is a process of assigning a label to every pixel in an image such that pixels with the same label are part of the same source. Detected sources must have a minimum number of connected pixels that are each greater than a specified threshold value in an image.\n",
    "\n",
    "The threshold level is usually defined as some multiple of the background noise (sigma level) above the background. This can be specified either as a per-pixel threshold image or a single value for the whole image.\n",
    "\n",
    "The image is usually filtered before thresholding to smooth the noise and maximize the detectability of objects with a shape similar to the filter kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to subtract the background from the image. Even though the background has already been subtracted from this dataset, we'll still perform that step as an example for other datasets.\n",
    "\n",
    "In this example, we’ll use the `Background2D` class to produce a background and background noise image.  The background rms will be used later to define the detection threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from photutils.background import Background2D, MedianBackground\n",
    "\n",
    "bkg_estimator = MedianBackground()\n",
    "bkg = Background2D(data, (50, 50), filter_size=(3, 3),\n",
    "                   bkg_estimator=bkg_estimator)\n",
    "data -= bkg.background  # subtract the background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After subtracting the background, we need to define the detection threshold. In this example, we’ll define a 2D detection threshold image using the background RMS image calculate above. We set the threshold at the 2.0$\\sigma$ (per pixel) noise level (above the background)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 2.0 * bkg.background_rms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let’s convolve the background-subtracted data with a 2D Gaussian kernel with a FWHM of 3 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.convolution import convolve\n",
    "from photutils.segmentation import make_2dgaussian_kernel\n",
    "\n",
    "kernel = make_2dgaussian_kernel(3.0, size=9)  # FWHM = 3.0\n",
    "convolved_data = convolve(data, kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to detect the sources in the background-subtracted convolved image. Let’s find sources that have 5 connected pixels that are each greater than the corresponding pixel-wise threshold level defined above (i.e., 2.0$\\sigma$ per pixel above the background). For this we use the [detect_sources](https://photutils.readthedocs.io/en/stable/api/photutils.segmentation.detect_sources.html) function.\n",
    "\n",
    "Note that by default “connected pixels” means “8-connected” pixels, where pixels touch along their edges or corners. One can also use “4-connected” pixels that touch only along their edges by setting connectivity=4:\n",
    "\n",
    "\"8-connected\" pixels touch along their edges or corners. \"4-connected\" pixels touch along their edges. For reference, SourceExtractor uses \"8-connected\" pixels.\n",
    "\n",
    "```\n",
    "8-connected      4-connected\n",
    "(default)\n",
    "\n",
    "  1 1 1            0 1 0\n",
    "  1 x 1            1 x 1\n",
    "  1 1 1            0 1 0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from photutils.segmentation import detect_sources\n",
    "\n",
    "npixels = 5\n",
    "segment_map = detect_sources(convolved_data, threshold, npixels)\n",
    "\n",
    "print('Found {0} sources'.format(segment_map.nlabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a segmentation image ([SegmentationImage](https://photutils.readthedocs.io/en/stable/api/photutils.segmentation.SegmentationImage.html#photutils.segmentation.SegmentationImage) object).  The segmentation image is an array with the same size as the science image in which each detected source is labeled with a unique integer value (>= 1).  Background pixels have a value of 0.  As a simple example, a segmentation map containing two distinct sources (labeled 1 and 2) might look like this:\n",
    "\n",
    "```\n",
    "0 0 0 0 0 0 0 0 0 0\n",
    "0 1 1 0 0 0 0 0 0 0\n",
    "1 1 1 1 1 0 0 0 2 0\n",
    "1 1 1 1 0 0 0 2 2 2\n",
    "1 1 1 0 0 0 2 2 2 2\n",
    "1 1 1 1 0 0 0 2 2 0\n",
    "1 1 0 0 0 0 2 2 0 0\n",
    "0 1 0 0 0 0 2 0 0 0\n",
    "0 0 0 0 0 0 0 0 0 0\n",
    "```\n",
    "where all of the pixels labeled `1` belong to the first source, all those labeled `2` belong to the second, and all those labeled `0` are background pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display the segmentation image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 10))\n",
    "ax1.imshow(data, norm=norm)\n",
    "lbl1 = ax1.set_title('Data')\n",
    "segment_map.imshow(ax=ax2)\n",
    "lbl2 = ax2.set_title('Segmentation Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source deblending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Comparing the data array with the segmentation image, we see that several detected sources were blended together.  We can deblend them using the [deblend_sources](https://photutils.readthedocs.io/en/stable/api/photutils.segmentation.deblend_sources.html#photutils.segmentation.deblend_sources) function, which uses a combination of multi-thresholding and watershed segmentation.\n",
    "\n",
    "The amount of deblending can be controlled with the two `deblend_sources` keywords `nlevels` and `contrast`:\n",
    "\n",
    "- `nlevels` is the number of multi-thresholding levels to use\n",
    "- `contrast` is the fraction of the total source flux that a local peak must have to be considered as a separate object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from photutils.segmentation import deblend_sources\n",
    "\n",
    "segment_map2 = deblend_sources(convolved_data, segment_map, npixels,\n",
    "                               contrast=0.001, nlevels=32, progress_bar=False)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 8))\n",
    "ax1.imshow(data, norm=norm)\n",
    "ax1.set_title('Data')\n",
    "segment_map.imshow(ax=ax2)\n",
    "ax2.set_title('Original Segmentation Image')\n",
    "segment_map2.imshow(ax=ax3)\n",
    "ax3.set_title('Deblended Segmentation Image')\n",
    "\n",
    "print('Found {0} sources'.format(segment_map2.nlabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the segmentation image, we observe that the sources were successfully deblended. We have 6 additional unique sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SourceFinder class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `SourceFinder` class is a convenience class that combines the functionality of `detect_sources` and `deblend_sources`. After defining the `SourceFinder` object with the desired detection and deblending parameters, you call it with the background-subtracted (convolved) image and threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from photutils.segmentation import SourceFinder\n",
    "\n",
    "finder = SourceFinder(npixels=npixels, deblend=True, progress_bar=False)\n",
    "segment_map3 = finder(convolved_data, threshold)\n",
    "axim = segment_map3.imshow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying a Segmentation Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `SegmentationImage` object provides several methods that can be used to visualize or modify itself (e.g., combining labels, removing labels, removing border segments) prior to measuring source photometry and other source properties, including:\n",
    "\n",
    "* `reassign_label()`: Reassign one or more label numbers.\n",
    "\n",
    "* `relabel_consecutive()`: Reassign the label numbers consecutively, such that there are no missing label numbers.\n",
    "\n",
    "* `keep_labels()`: Keep only the specified labels.\n",
    "\n",
    "* `remove_labels()`: Remove one or more labels.\n",
    "\n",
    "* `remove_border_labels()`: Remove labeled segments near the image border.\n",
    "\n",
    "* `remove_masked_labels()`: Remove labeled segments located within a masked region.\n",
    "\n",
    "* `outline_segments()`: Outline the labeled segments for plotting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Photometry, Centroids, and Shape Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [SourceCatalog](https://photutils.readthedocs.io/en/stable/api/photutils.segmentation.SourceCatalog.html#photutils.segmentation.SourceCatalog) class is the primary tool for measuring the photometry, centroids, and shape/morphological properties of sources defined in a segmentation image. In its most basic form, it takes as input the (background-subtracted) image and the segmentation image. Usually the convolved image is also input, from which the source centroids and shape/morphological properties are measured (if not input, the unconvolved image is used instead)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s continue our example from above and measure the properties of the detected sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.units as u\n",
    "from photutils.segmentation import SourceCatalog\n",
    "\n",
    "unit = u.electron / u.s\n",
    "catalog = SourceCatalog(data << unit, segment_map3, error=total_error << unit,\n",
    "                        convolved_data=convolved_data << unit, wcs=wcs)\n",
    "catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `catalog` variable is a `SourceCatalog` object. The properties of each source can be accessed using `SourceCatalog` attributes or they can be output to an Astropy `QTable` using the `to_table()` method.\n",
    "\n",
    "Here we’ll use the `to_table()` method to generate a `QTable` of source photometry and properties. Each row in the table represents a source. The columns represent the calculated source properties. The label column corresponds to the label value in the input segmentation image.\n",
    "\n",
    "Please see the [SourceCatalog documentation](https://photutils.readthedocs.io/en/latest/api/photutils.segmentation.SourceCatalog.html#photutils.segmentation.SourceCatalog) for a complete list of the available source properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_tbl = catalog.to_table()\n",
    "catalog_tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save this table to an ESCV file so it can be used later in the exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_tbl.write('xdf_f160w_catalog.ecsv', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also save the `SegmentationImage` to a FITS file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits.writeto('xdf_f160w_segm.fits', segment_map3.data, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also access the source properties as attributes of the `SourceCatalog` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.xcentroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.eccentricity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isophotal flux\n",
    "catalog.segment_flux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's plot the elliptical Kron apertures (based on the shapes of each source) for each source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(data, norm=norm)\n",
    "for obj in catalog:\n",
    "    obj.kron_aperture.plot(color='red', lw=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `SourceCatalog` object can also be indexed or sliced to select a subset of sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objs = catalog[0:5]  # the first 5 sources\n",
    "objs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subsets can also be created using a label number or list of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [1, 2, 5, 7, 21]\n",
    "objs = catalog.get_labels(labels)\n",
    "objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objs.xcentroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "objs_tbl = objs.to_table()\n",
    "objs_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a single object (label=12)\n",
    "obj = catalog.get_label(12)\n",
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the cutouts of the segmentation image, data, and error images for this source. These are all available as `SourceCatalog` attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8), ncols=3)\n",
    "ax[0].imshow(obj.segment)\n",
    "ax[0].set_title('Source label={} Segment'.format(obj.label))\n",
    "ax[1].imshow(obj.data_ma)\n",
    "ax[1].set_title('Source label={} Data'.format(obj.label))\n",
    "ax[2].imshow(obj.error_ma)\n",
    "ax[2].set_title('Source label={} Error'.format(obj.label));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's plot the bounding box for this source on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(data, norm=norm)\n",
    "obj.bbox.plot(color='red', lw=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [**data/**](data) subdirectory also contains a WFC3/IR F105W image of the same field used for the preceding examples. The F105W and F160W images are pixel aligned, so sources in the F105W image are located at the same pixel positions as the F160W image (if they are visible in the F105W image)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the F105W isophotal fluxes using the source segments defined by the F160W detection image.\n",
    "\n",
    "Hints:\n",
    "\n",
    "* Because the images are pixel aligned, the F160W segmentation image can be directly applied to the F105W image.\n",
    "\n",
    "* We previously saved the F160W segmentation image in a file called `xdf_f160w_segm.fits`.\n",
    "\n",
    "* The isophotal fluxes are found in the `segment_flux` attribute of the `SourceCatalog`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you prefer to load the solution, uncomment the line below and run the cell twice (once to load the solution and once more to run it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load 04-segmentation_exercise1_solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the $Y_{105} - H_{160}$ (F105W $-$ F160W) isophotal colors for all sources detected in the F160W image.  Which sources have the three reddest $Y_{105} - H_{160}$ colors?\n",
    "\n",
    "The WFC3/IR F105W and F160W AB magnitude zero points are `26.2687` and `25.9463`, respectively.\n",
    "\n",
    "Hints:\n",
    "\n",
    "* We previously saved the F160W source catalog table in a file called `xdf_f160w_catalog.ecsv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you prefer to load the solution, uncomment the line below and run the cell twice (once to load the solution and once more to run it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load 04-segmentation_exercise2_solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning alert-block\">\n",
    "<h3 style='margin-top: 0;'>Learn More</h3>\n",
    "\n",
    "The [PSF photometry](05-psf_photometry.ipynb) notebook covers:\n",
    "\n",
    "- PSF photometry using simulated 2D Gaussian PSFs, using:\n",
    "  - BasicPSFPhotometry\n",
    "  - IterativelySubtractedPSFPhotometry\n",
    "  - DAOPhotPSFPhotometry\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
